{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AVALON Nuclear AI Crisis - Data Analysis\n",
    "## Imperial College London - Claude Hacks\n",
    "\n",
    "**Objective**: Analyze AVALON's misaligned behavior and build models to predict true nuclear risk vs AVALON's biased recommendations.\n",
    "\n",
    "**Problem Statement**: AVALON overreacts to public anxiety, social media rumors, and regulatory scrutiny instead of focusing on true physical risk. We will:\n",
    "1. Identify patterns in AVALON's decision-making biases\n",
    "2. Build predictive models for true risk and incidents\n",
    "3. Compare our models to AVALON's flawed recommendations\n",
    "4. Provide actionable insights for operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plotting settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print('Libraries loaded successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('avalon_nuclear.csv')\n",
    "\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick data overview\n",
    "print(\"=== DATA OVERVIEW ===\")\n",
    "print(f\"Total observations: {len(df):,}\")\n",
    "print(f\"Total features: {df.shape[1]}\")\n",
    "print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"\\nData types:\")\n",
    "print(df.dtypes.value_counts())\n",
    "print(f\"\\nMemory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)\n",
    "\n",
    "### 2.1 Target Variables Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze target variables\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('Target Variables Distribution Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# True Risk Level\n",
    "true_risk_counts = df['true_risk_level'].value_counts().sort_index()\n",
    "axes[0, 0].bar(true_risk_counts.index, true_risk_counts.values, color='steelblue', alpha=0.7)\n",
    "axes[0, 0].set_title('True Risk Level Distribution', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Risk Level (0=Low, 3=Very High)')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "for i, v in enumerate(true_risk_counts.values):\n",
    "    axes[0, 0].text(i, v + 50, f'{v}\\n({v/len(df)*100:.1f}%)', ha='center', fontweight='bold')\n",
    "\n",
    "# Incident Occurred\n",
    "incident_counts = df['incident_occurred'].value_counts()\n",
    "axes[0, 1].bar(['No Incident', 'Incident'], incident_counts.values, color=['green', 'red'], alpha=0.7)\n",
    "axes[0, 1].set_title('Actual Incidents Distribution', fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Count')\n",
    "for i, v in enumerate(incident_counts.values):\n",
    "    axes[0, 1].text(i, v + 50, f'{v}\\n({v/len(df)*100:.1f}%)', ha='center', fontweight='bold')\n",
    "\n",
    "# AVALON Evacuation Recommendation\n",
    "evac_counts = df['avalon_evac_recommendation'].value_counts()\n",
    "axes[0, 2].bar(['No Evac', 'Evacuate'], evac_counts.values, color=['lightblue', 'orange'], alpha=0.7)\n",
    "axes[0, 2].set_title('AVALON Evacuation Recommendations', fontweight='bold')\n",
    "axes[0, 2].set_ylabel('Count')\n",
    "for i, v in enumerate(evac_counts.values):\n",
    "    axes[0, 2].text(i, v + 50, f'{v}\\n({v/len(df)*100:.1f}%)', ha='center', fontweight='bold')\n",
    "\n",
    "# AVALON Shutdown Recommendation\n",
    "shutdown_counts = df['avalon_shutdown_recommendation'].value_counts()\n",
    "axes[1, 0].bar(['No Shutdown', 'Shutdown'], shutdown_counts.values, color=['lightgreen', 'darkred'], alpha=0.7)\n",
    "axes[1, 0].set_title('AVALON Shutdown Recommendations', fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "for i, v in enumerate(shutdown_counts.values):\n",
    "    axes[1, 0].text(i, v + 50, f'{v}\\n({v/len(df)*100:.1f}%)', ha='center', fontweight='bold')\n",
    "\n",
    "# Human Override\n",
    "override_counts = df['human_override'].value_counts()\n",
    "axes[1, 1].bar(['No Override', 'Override'], override_counts.values, color=['gray', 'purple'], alpha=0.7)\n",
    "axes[1, 1].set_title('Human Overrides', fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Count')\n",
    "for i, v in enumerate(override_counts.values):\n",
    "    axes[1, 1].text(i, v + 50, f'{v}\\n({v/len(df)*100:.1f}%)', ha='center', fontweight='bold')\n",
    "\n",
    "# Sensor Anomaly\n",
    "sensor_counts = df['sensor_anomaly_flag'].value_counts()\n",
    "axes[1, 2].bar(['No Anomaly', 'Anomaly'], sensor_counts.values, color=['lightgray', 'yellow'], alpha=0.7)\n",
    "axes[1, 2].set_title('Sensor Anomalies', fontweight='bold')\n",
    "axes[1, 2].set_ylabel('Count')\n",
    "for i, v in enumerate(sensor_counts.values):\n",
    "    axes[1, 2].text(i, v + 50, f'{v}\\n({v/len(df)*100:.1f}%)', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\u26a0\ufe0f KEY OBSERVATION: AVALON recommends shutdown in 70% of cases, but only 13% result in actual incidents!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 AVALON's Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix style analysis\n",
    "print(\"=== AVALON SHUTDOWN RECOMMENDATION vs ACTUAL INCIDENTS ===\")\n",
    "print(pd.crosstab(df['avalon_shutdown_recommendation'], df['incident_occurred'], \n",
    "                  rownames=['AVALON Shutdown'], colnames=['Actual Incident'], margins=True))\n",
    "\n",
    "print(\"\\n=== AVALON EVACUATION RECOMMENDATION vs ACTUAL INCIDENTS ===\")\n",
    "print(pd.crosstab(df['avalon_evac_recommendation'], df['incident_occurred'], \n",
    "                  rownames=['AVALON Evac'], colnames=['Actual Incident'], margins=True))\n",
    "\n",
    "# Calculate AVALON's accuracy\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"\\n=== AVALON SHUTDOWN PERFORMANCE METRICS ===\")\n",
    "print(f\"Accuracy: {accuracy_score(df['incident_occurred'], df['avalon_shutdown_recommendation']):.3f}\")\n",
    "print(f\"Precision: {precision_score(df['incident_occurred'], df['avalon_shutdown_recommendation']):.3f}\")\n",
    "print(f\"Recall: {recall_score(df['incident_occurred'], df['avalon_shutdown_recommendation']):.3f}\")\n",
    "print(f\"F1-Score: {f1_score(df['incident_occurred'], df['avalon_shutdown_recommendation']):.3f}\")\n",
    "\n",
    "# False positives analysis\n",
    "false_positives = ((df['avalon_shutdown_recommendation'] == 1) & (df['incident_occurred'] == 0)).sum()\n",
    "false_negatives = ((df['avalon_shutdown_recommendation'] == 0) & (df['incident_occurred'] == 1)).sum()\n",
    "\n",
    "print(f\"\\n\u26a0\ufe0f False Positives (unnecessary shutdowns): {false_positives} ({false_positives/len(df)*100:.1f}%)\")\n",
    "print(f\"\u26a0\ufe0f False Negatives (missed incidents): {false_negatives} ({false_negatives/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Geographic Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Country analysis\n",
    "country_stats = df.groupby('country').agg({\n",
    "    'incident_occurred': ['count', 'sum', 'mean'],\n",
    "    'true_risk_level': 'mean',\n",
    "    'avalon_shutdown_recommendation': 'mean'\n",
    "}).round(3)\n",
    "\n",
    "country_stats.columns = ['Total_Plants', 'Incidents', 'Incident_Rate', 'Avg_True_Risk', 'AVALON_Shutdown_Rate']\n",
    "country_stats = country_stats.sort_values('Incidents', ascending=False)\n",
    "\n",
    "print(\"=== TOP 15 COUNTRIES BY INCIDENT COUNT ===\")\n",
    "print(country_stats.head(15))\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "top_countries = country_stats.head(10)\n",
    "axes[0].barh(top_countries.index, top_countries['Incidents'], color='crimson', alpha=0.7)\n",
    "axes[0].set_xlabel('Number of Incidents')\n",
    "axes[0].set_title('Top 10 Countries by Incidents', fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "axes[1].scatter(country_stats['Avg_True_Risk'], country_stats['AVALON_Shutdown_Rate'], \n",
    "                s=country_stats['Total_Plants']*2, alpha=0.6, c='blue')\n",
    "axes[1].set_xlabel('Average True Risk Level')\n",
    "axes[1].set_ylabel('AVALON Shutdown Rate')\n",
    "axes[1].set_title('True Risk vs AVALON Shutdown Rate by Country', fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Technical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key technical features\n",
    "technical_features = [\n",
    "    'core_temp_c', 'coolant_pressure_bar', 'neutron_flux', \n",
    "    'control_rod_position_pct', 'coolant_flow_rate',\n",
    "    'radiation_inside_uSv', 'radiation_outside_uSv'\n",
    "]\n",
    "\n",
    "# Compare distributions for incidents vs no incidents\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 14))\n",
    "axes = axes.flatten()\n",
    "fig.suptitle('Technical Features: Incidents vs No Incidents', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, feature in enumerate(technical_features):\n",
    "    incident_data = df[df['incident_occurred'] == 1][feature]\n",
    "    no_incident_data = df[df['incident_occurred'] == 0][feature]\n",
    "    \n",
    "    axes[idx].hist(no_incident_data, bins=30, alpha=0.6, label='No Incident', color='green', density=True)\n",
    "    axes[idx].hist(incident_data, bins=30, alpha=0.6, label='Incident', color='red', density=True)\n",
    "    axes[idx].set_title(feature, fontweight='bold')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].set_ylabel('Density')\n",
    "\n",
    "# Remove extra subplots\n",
    "for idx in range(len(technical_features), len(axes)):\n",
    "    fig.delaxes(axes[idx])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistical tests\n",
    "print(\"\\n=== STATISTICAL SIGNIFICANCE (t-test) ===\")\n",
    "print(\"Testing if technical features differ between incident/no-incident cases:\\n\")\n",
    "for feature in technical_features:\n",
    "    incident_data = df[df['incident_occurred'] == 1][feature]\n",
    "    no_incident_data = df[df['incident_occurred'] == 0][feature]\n",
    "    t_stat, p_value = stats.ttest_ind(incident_data, no_incident_data)\n",
    "    significance = \"***\" if p_value < 0.001 else \"**\" if p_value < 0.01 else \"*\" if p_value < 0.05 else \"n.s.\"\n",
    "    print(f\"{feature:30s} p-value: {p_value:.4f} {significance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 AVALON Bias Analysis - Social vs Physical Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature groups\n",
    "physical_risk_features = [\n",
    "    'core_temp_c', 'coolant_pressure_bar', 'neutron_flux',\n",
    "    'radiation_inside_uSv', 'radiation_outside_uSv', 'maintenance_score'\n",
    "]\n",
    "\n",
    "social_bias_features = [\n",
    "    'public_anxiety_index', 'social_media_rumour_index', 'regulator_scrutiny_score'\n",
    "]\n",
    "\n",
    "# Correlation with AVALON decisions\n",
    "print(\"=== CORRELATION WITH AVALON SHUTDOWN RECOMMENDATION ===\")\n",
    "print(\"\\nPhysical Risk Features:\")\n",
    "for feature in physical_risk_features:\n",
    "    corr = df[feature].corr(df['avalon_shutdown_recommendation'])\n",
    "    print(f\"{feature:30s}: {corr:+.3f}\")\n",
    "\n",
    "print(\"\\nSocial Bias Features (suspected over-weighting):\")\n",
    "for feature in social_bias_features:\n",
    "    corr = df[feature].corr(df['avalon_shutdown_recommendation'])\n",
    "    print(f\"{feature:30s}: {corr:+.3f}\")\n",
    "\n",
    "print(\"\\n=== CORRELATION WITH TRUE RISK LEVEL ===\")\n",
    "print(\"\\nPhysical Risk Features:\")\n",
    "for feature in physical_risk_features:\n",
    "    corr = df[feature].corr(df['true_risk_level'])\n",
    "    print(f\"{feature:30s}: {corr:+.3f}\")\n",
    "\n",
    "print(\"\\nSocial Bias Features:\")\n",
    "for feature in social_bias_features:\n",
    "    corr = df[feature].corr(df['true_risk_level'])\n",
    "    print(f\"{feature:30s}: {corr:+.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of bias\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('AVALON Bias: Social Features vs Physical Risk', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, feature in enumerate(social_bias_features):\n",
    "    # AVALON shutdown vs social feature\n",
    "    axes[0, idx].scatter(df[feature], df['avalon_shutdown_recommendation'], \n",
    "                         alpha=0.3, c='red', s=10)\n",
    "    axes[0, idx].set_xlabel(feature)\n",
    "    axes[0, idx].set_ylabel('AVALON Shutdown')\n",
    "    axes[0, idx].set_title(f'{feature} vs AVALON Decision', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    # True risk vs social feature\n",
    "    axes[1, idx].scatter(df[feature], df['true_risk_level'], \n",
    "                         alpha=0.3, c='blue', s=10)\n",
    "    axes[1, idx].set_xlabel(feature)\n",
    "    axes[1, idx].set_ylabel('True Risk Level')\n",
    "    axes[1, idx].set_title(f'{feature} vs True Risk', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\ud83d\udca1 If social features correlate strongly with AVALON decisions but weakly with true risk,\")\n",
    "print(\"   this confirms AVALON's misalignment!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select key features for correlation\n",
    "key_features = [\n",
    "    'core_temp_c', 'coolant_pressure_bar', 'neutron_flux',\n",
    "    'radiation_inside_uSv', 'maintenance_score',\n",
    "    'public_anxiety_index', 'social_media_rumour_index', 'regulator_scrutiny_score',\n",
    "    'avalon_raw_risk_score', 'avalon_learned_reward_score',\n",
    "    'true_risk_level', 'avalon_shutdown_recommendation', 'incident_occurred'\n",
    "]\n",
    "\n",
    "# Correlation matrix\n",
    "corr_matrix = df[key_features].corr()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(16, 14))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Heatmap: Key Features', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Top correlations with incident_occurred\n",
    "print(\"\\n=== TOP CORRELATIONS WITH ACTUAL INCIDENTS ===\")\n",
    "incident_corr = df.corr()['incident_occurred'].sort_values(ascending=False)\n",
    "print(incident_corr.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yearly trends\n",
    "yearly_stats = df.groupby('year').agg({\n",
    "    'incident_occurred': 'mean',\n",
    "    'avalon_shutdown_recommendation': 'mean',\n",
    "    'true_risk_level': 'mean',\n",
    "    'public_anxiety_index': 'mean'\n",
    "})\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 10))\n",
    "fig.suptitle('Temporal Trends (1991-2025)', fontsize=16, fontweight='bold')\n",
    "\n",
    "axes[0, 0].plot(yearly_stats.index, yearly_stats['incident_occurred'], marker='o', color='red', linewidth=2)\n",
    "axes[0, 0].set_title('Incident Rate Over Time', fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Incident Rate')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[0, 1].plot(yearly_stats.index, yearly_stats['avalon_shutdown_recommendation'], marker='s', color='orange', linewidth=2)\n",
    "axes[0, 1].set_title('AVALON Shutdown Rate Over Time', fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Shutdown Rate')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 0].plot(yearly_stats.index, yearly_stats['true_risk_level'], marker='^', color='blue', linewidth=2)\n",
    "axes[1, 0].set_title('Average True Risk Over Time', fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Avg True Risk')\n",
    "axes[1, 0].set_xlabel('Year')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 1].plot(yearly_stats.index, yearly_stats['public_anxiety_index'], marker='d', color='purple', linewidth=2)\n",
    "axes[1, 1].set_title('Public Anxiety Over Time', fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Avg Anxiety Index')\n",
    "axes[1, 1].set_xlabel('Year')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 AVALON Score Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare AVALON's two scoring systems\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "# Raw vs Learned scores\n",
    "axes[0].scatter(df['avalon_raw_risk_score'], df['avalon_learned_reward_score'], \n",
    "                alpha=0.4, c=df['incident_occurred'], cmap='RdYlGn_r', s=20)\n",
    "axes[0].set_xlabel('AVALON Raw Risk Score')\n",
    "axes[0].set_ylabel('AVALON Learned Reward Score')\n",
    "axes[0].set_title('Raw Risk vs Learned Reward Score', fontweight='bold')\n",
    "axes[0].plot([df['avalon_raw_risk_score'].min(), df['avalon_raw_risk_score'].max()],\n",
    "             [df['avalon_raw_risk_score'].min(), df['avalon_raw_risk_score'].max()],\n",
    "             'r--', alpha=0.5, label='y=x')\n",
    "axes[0].legend()\n",
    "\n",
    "# Learned score vs True risk\n",
    "df.boxplot(column='avalon_learned_reward_score', by='true_risk_level', ax=axes[1])\n",
    "axes[1].set_title('Learned Score by True Risk Level', fontweight='bold')\n",
    "axes[1].set_xlabel('True Risk Level')\n",
    "axes[1].set_ylabel('AVALON Learned Reward Score')\n",
    "\n",
    "# Raw score vs True risk\n",
    "df.boxplot(column='avalon_raw_risk_score', by='true_risk_level', ax=axes[2])\n",
    "axes[2].set_title('Raw Score by True Risk Level', fontweight='bold')\n",
    "axes[2].set_xlabel('True Risk Level')\n",
    "axes[2].set_ylabel('AVALON Raw Risk Score')\n",
    "\n",
    "plt.suptitle('')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== AVALON SCORES CORRELATION ===\")\n",
    "print(f\"Raw score vs Learned score: {df['avalon_raw_risk_score'].corr(df['avalon_learned_reward_score']):.3f}\")\n",
    "print(f\"Raw score vs True risk: {df['avalon_raw_risk_score'].corr(df['true_risk_level']):.3f}\")\n",
    "print(f\"Learned score vs True risk: {df['avalon_learned_reward_score'].corr(df['true_risk_level']):.3f}\")\n",
    "print(f\"Raw score vs Incidents: {df['avalon_raw_risk_score'].corr(df['incident_occurred']):.3f}\")\n",
    "print(f\"Learned score vs Incidents: {df['avalon_learned_reward_score'].corr(df['incident_occurred']):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Key Insights from EDA\n",
    "\n",
    "### Summary of Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"KEY INSIGHTS FROM EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. AVALON OVERREACTION:\")\n",
    "print(f\"   - AVALON recommends shutdown in {(df['avalon_shutdown_recommendation'].mean()*100):.1f}% of cases\")\n",
    "print(f\"   - Only {(df['incident_occurred'].mean()*100):.1f}% of cases result in actual incidents\")\n",
    "print(f\"   - This represents a {(df['avalon_shutdown_recommendation'].mean() / df['incident_occurred'].mean()):.1f}x overreaction rate\")\n",
    "\n",
    "print(\"\\n2. SOCIAL BIAS:\")\n",
    "social_corr_avalon = df[social_bias_features].corrwith(df['avalon_shutdown_recommendation']).mean()\n",
    "social_corr_true = df[social_bias_features].corrwith(df['true_risk_level']).mean()\n",
    "print(f\"   - Avg correlation of social features with AVALON decisions: {social_corr_avalon:.3f}\")\n",
    "print(f\"   - Avg correlation of social features with true risk: {social_corr_true:.3f}\")\n",
    "print(f\"   - Bias ratio: {abs(social_corr_avalon / social_corr_true):.2f}x\")\n",
    "\n",
    "print(\"\\n3. FALSE POSITIVES:\")\n",
    "fp_rate = ((df['avalon_shutdown_recommendation'] == 1) & (df['incident_occurred'] == 0)).mean()\n",
    "print(f\"   - {(fp_rate*100):.1f}% of cases are unnecessary shutdowns\")\n",
    "print(f\"   - This could destabilize the energy grid\")\n",
    "\n",
    "print(\"\\n4. HUMAN TRUST:\")\n",
    "print(f\"   - Humans override AVALON in only {df['human_override'].sum()} cases ({(df['human_override'].mean()*100):.2f}%)\")\n",
    "print(f\"   - This suggests dangerous over-reliance on a flawed system\")\n",
    "\n",
    "print(\"\\n5. DATA QUALITY:\")\n",
    "print(f\"   - {df['sensor_anomaly_flag'].sum()} sensor anomalies detected ({(df['sensor_anomaly_flag'].mean()*100):.1f}%)\")\n",
    "print(f\"   - Faulty sensors may contribute to AVALON's poor decisions\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing\n",
    "\n",
    "### 4.1 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for modeling\n",
    "df_model = df.copy()\n",
    "\n",
    "# Feature engineering\n",
    "print(\"=== FEATURE ENGINEERING ===\")\n",
    "\n",
    "# 1. Reactor risk indicators\n",
    "df_model['temp_pressure_risk'] = df_model['core_temp_c'] * df_model['coolant_pressure_bar'] / 1000\n",
    "df_model['radiation_differential'] = df_model['radiation_inside_uSv'] - df_model['radiation_outside_uSv']\n",
    "df_model['control_efficiency'] = df_model['control_rod_position_pct'] * df_model['neutron_flux'] / 100\n",
    "\n",
    "# 2. Maintenance risk\n",
    "df_model['maintenance_risk'] = df_model['days_since_maintenance'] / (df_model['maintenance_score'] + 1)\n",
    "\n",
    "# 3. Social pressure index (the bias source)\n",
    "df_model['social_pressure_index'] = (\n",
    "    df_model['public_anxiety_index'] + \n",
    "    df_model['social_media_rumour_index'] + \n",
    "    df_model['regulator_scrutiny_score']\n",
    ") / 3\n",
    "\n",
    "# 4. Physical risk index (true indicators)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "physical_cols = ['core_temp_c', 'coolant_pressure_bar', 'neutron_flux', \n",
    "                 'radiation_inside_uSv', 'radiation_outside_uSv']\n",
    "scaler_temp = StandardScaler()\n",
    "physical_normalized = scaler_temp.fit_transform(df_model[physical_cols])\n",
    "df_model['physical_risk_index'] = physical_normalized.mean(axis=1)\n",
    "\n",
    "# 5. Age-power interaction\n",
    "df_model['age_power_ratio'] = df_model['reactor_age_years'] * df_model['reactor_nominal_power_mw'] / 1000\n",
    "\n",
    "# 6. Population risk\n",
    "df_model['population_risk'] = df_model['population_within_30km'] * df_model['true_risk_level'] / 1000\n",
    "\n",
    "print(f\"New features created: {len([c for c in df_model.columns if c not in df.columns])}\")\n",
    "print(f\"Total features now: {df_model.shape[1]}\")\n",
    "print(\"\nNew feature preview:\")\n",
    "print(df_model[['temp_pressure_risk', 'social_pressure_index', 'physical_risk_index', \n",
    "               'maintenance_risk', 'age_power_ratio']].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}