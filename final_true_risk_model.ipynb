{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Comprehensive Model: True Risk Level Prediction\n",
    "## Using Regularization, Normalization, and Advanced ML Techniques\n",
    "\n",
    "**Target**: `true_risk_level` (0, 1, 2, 3)\n",
    "\n",
    "**Techniques Applied**:\n",
    "- Multiple normalization methods (Standard, MinMax, Robust)\n",
    "- Regularization (Ridge, Lasso, ElasticNet, L1/L2 for neural nets)\n",
    "- Feature engineering and selection\n",
    "- Cross-validation for robust evaluation\n",
    "- Hyperparameter tuning\n",
    "- Class balancing\n",
    "- Ensemble methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightgbm'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mneighbors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KNeighborsClassifier\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightgbm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LGBMClassifier\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Imbalanced learning\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimblearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mover_sampling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'lightgbm'"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, confusion_matrix,\n",
    "    f1_score, precision_score, recall_score, roc_auc_score\n",
    ")\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, GradientBoostingClassifier,\n",
    "    ExtraTreesClassifier, VotingClassifier, StackingClassifier\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Imbalanced learning\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "# Settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print('Libraries loaded successfully!')\n",
    "print(f'TensorFlow version: {tf.__version__}')\n",
    "print(f'GPU available: {len(tf.config.list_physical_devices(\"GPU\"))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('avalon_nuclear.csv')\n",
    "\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"\\nTarget Distribution:\")\n",
    "print(df['true_risk_level'].value_counts().sort_index())\n",
    "print(f\"\\nClass Balance:\")\n",
    "print(df['true_risk_level'].value_counts(normalize=True).sort_index())\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nMissing values: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create enhanced features\n",
    "print('=== FEATURE ENGINEERING ===\")\n",
    "\n",
    "df_model = df.copy()\n",
    "\n",
    "# 1. Physical risk indicators\n",
    "df_model['temp_pressure_interaction'] = df_model['core_temp_c'] * df_model['coolant_pressure_bar'] / 1000\n",
    "df_model['radiation_ratio'] = df_model['radiation_inside_uSv'] / (df_model['radiation_outside_uSv'] + 0.01)\n",
    "df_model['radiation_differential'] = df_model['radiation_inside_uSv'] - df_model['radiation_outside_uSv']\n",
    "df_model['control_efficiency'] = df_model['control_rod_position_pct'] * df_model['neutron_flux'] / 100\n",
    "df_model['coolant_temp_flow_ratio'] = df_model['core_temp_c'] / (df_model['coolant_flow_rate'] + 1)\n",
    "\n",
    "# 2. Maintenance and operational risks\n",
    "df_model['maintenance_risk_score'] = df_model['days_since_maintenance'] / (df_model['maintenance_score'] + 1)\n",
    "df_model['fatigue_maintenance_interaction'] = df_model['staff_fatigue_index'] * df_model['days_since_maintenance'] / 100\n",
    "df_model['load_age_interaction'] = df_model['load_factor_pct'] * df_model['reactor_age_years'] / 100\n",
    "\n",
    "# 3. External risk factors\n",
    "df_model['environmental_risk_composite'] = (\n",
    "    df_model['weather_severity_index'] + \n",
    "    df_model['seismic_activity_index'] + \n",
    "    df_model['env_risk_index']\n",
    ") / 3\n",
    "\n",
    "df_model['social_pressure_index'] = (\n",
    "    df_model['public_anxiety_index'] + \n",
    "    df_model['social_media_rumour_index'] + \n",
    "    df_model['regulator_scrutiny_score']\n",
    ") / 3\n",
    "\n",
    "# 4. Power and capacity indicators\n",
    "df_model['power_capacity'] = df_model['reactor_nominal_power_mw'] * df_model['load_factor_pct'] / 100\n",
    "df_model['age_power_risk'] = df_model['reactor_age_years'] * df_model['reactor_nominal_power_mw'] / 1000\n",
    "\n",
    "# 5. Population exposure risk\n",
    "df_model['population_exposure'] = df_model['population_within_30km'] * df_model['radiation_outside_uSv'] / 1000\n",
    "\n",
    "# 6. System health indicators\n",
    "df_model['system_reliability'] = (\n",
    "    df_model['backup_generator_health'] + \n",
    "    df_model['maintenance_score'] - \n",
    "    df_model['staff_fatigue_index']\n",
    ") / 3\n",
    "\n",
    "# 7. Polynomial features for key variables\n",
    "df_model['core_temp_squared'] = df_model['core_temp_c'] ** 2\n",
    "df_model['coolant_pressure_squared'] = df_model['coolant_pressure_bar'] ** 2\n",
    "df_model['neutron_flux_squared'] = df_model['neutron_flux'] ** 2\n",
    "\n",
    "# 8. Logarithmic transformations for skewed features\n",
    "df_model['log_days_since_maintenance'] = np.log1p(df_model['days_since_maintenance'])\n",
    "df_model['log_population'] = np.log1p(df_model['population_within_30km'])\n",
    "\n",
    "print(f'New features created. Total features: {df_model.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "le_country = LabelEncoder()\n",
    "df_model['country_encoded'] = le_country.fit_transform(df_model['country'])\n",
    "\n",
    "le_reactor = LabelEncoder()\n",
    "df_model['reactor_type_encoded'] = le_reactor.fit_transform(df_model['reactor_type_code'])\n",
    "\n",
    "# Define feature sets\n",
    "exclude_cols = [\n",
    "    'country', 'true_risk_level', 'incident_occurred',\n",
    "    'avalon_evac_recommendation', 'avalon_shutdown_recommendation',\n",
    "    'human_override', 'avalon_raw_risk_score', 'avalon_learned_reward_score',\n",
    "    'reactor_type_code'\n",
    "]\n",
    "\n",
    "feature_cols = [col for col in df_model.columns if col not in exclude_cols]\n",
    "print(f'\\nTotal features for modeling: {len(feature_cols)}')\n",
    "print(f'Feature list: {feature_cols[:10]}...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare X and y\n",
    "X = df_model[feature_cols]\n",
    "y = df_model['true_risk_level']\n",
    "\n",
    "print(f'X shape: {X.shape}')\n",
    "print(f'y shape: {y.shape}')\n",
    "print(f'\\nTarget distribution:\\n{y.value_counts().sort_index()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Splitting and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split (stratified to preserve class distribution)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f'Train set: {X_train.shape}')\n",
    "print(f'Test set: {X_test.shape}')\n",
    "print(f'\\nTrain target distribution:\\n{y_train.value_counts().sort_index()}')\n",
    "print(f'\\nTest target distribution:\\n{y_test.value_counts().sort_index()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply multiple normalization techniques\n",
    "print('=== NORMALIZATION TECHNIQUES ===\")\n",
    "\n",
    "# 1. StandardScaler (zero mean, unit variance)\n",
    "scaler_standard = StandardScaler()\n",
    "X_train_standard = scaler_standard.fit_transform(X_train)\n",
    "X_test_standard = scaler_standard.transform(X_test)\n",
    "\n",
    "# 2. MinMaxScaler (scale to [0, 1])\n",
    "scaler_minmax = MinMaxScaler()\n",
    "X_train_minmax = scaler_minmax.fit_transform(X_train)\n",
    "X_test_minmax = scaler_minmax.transform(X_test)\n",
    "\n",
    "# 3. RobustScaler (robust to outliers)\n",
    "scaler_robust = RobustScaler()\n",
    "X_train_robust = scaler_robust.fit_transform(X_train)\n",
    "X_test_robust = scaler_robust.transform(X_test)\n",
    "\n",
    "print('StandardScaler: mean=0, std=1')\n",
    "print('MinMaxScaler: min=0, max=1')\n",
    "print('RobustScaler: uses median and IQR (robust to outliers)')\n",
    "print('\\nAll scalers fitted on training data and applied to test data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical feature selection\n",
    "print('=== FEATURE SELECTION ===\")\n",
    "\n",
    "# Use SelectKBest with ANOVA F-test\n",
    "selector = SelectKBest(score_func=f_classif, k=30)  # Select top 30 features\n",
    "selector.fit(X_train_standard, y_train)\n",
    "\n",
    "# Get selected feature indices and names\n",
    "selected_indices = selector.get_support(indices=True)\n",
    "selected_features = [feature_cols[i] for i in selected_indices]\n",
    "\n",
    "print(f'Selected {len(selected_features)} best features:')\n",
    "print(selected_features)\n",
    "\n",
    "# Feature scores\n",
    "feature_scores = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'score': selector.scores_\n",
    "}).sort_values('score', ascending=False)\n",
    "\n",
    "print(f'\\nTop 15 features by F-score:')\n",
    "print(feature_scores.head(15))\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_features = feature_scores.head(20)\n",
    "plt.barh(range(len(top_features)), top_features['score'], color='steelblue')\n",
    "plt.yticks(range(len(top_features)), top_features['feature'], fontsize=9)\n",
    "plt.xlabel('F-Score', fontweight='bold')\n",
    "plt.title('Top 20 Features by F-Score', fontweight='bold', fontsize=14)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training with Regularization\n",
    "\n",
    "### 5.1 Regularized Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== REGULARIZED LINEAR MODELS ===\")\n",
    "print('Using StandardScaler for linear models\\n')\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "linear_models = {}\n",
    "linear_results = []\n",
    "\n",
    "# 1. Logistic Regression with L2 (Ridge)\n",
    "print('Training Logistic Regression (L2)...')\n",
    "lr_l2 = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=1.0,  # Inverse regularization strength\n",
    "    max_iter=1000,\n",
    "    multi_class='multinomial',\n",
    "    solver='lbfgs',\n",
    "    random_state=42\n",
    ")\n",
    "lr_l2.fit(X_train_standard, y_train)\n",
    "lr_l2_pred = lr_l2.predict(X_test_standard)\n",
    "lr_l2_acc = accuracy_score(y_test, lr_l2_pred)\n",
    "lr_l2_f1 = f1_score(y_test, lr_l2_pred, average='weighted')\n",
    "linear_models['Logistic_L2'] = lr_l2\n",
    "linear_results.append({'Model': 'Logistic Regression (L2)', 'Accuracy': lr_l2_acc, 'F1-Score': lr_l2_f1})\n",
    "print(f'Accuracy: {lr_l2_acc:.4f}, F1-Score: {lr_l2_f1:.4f}')\n",
    "\n",
    "# 2. Logistic Regression with L1 (Lasso)\n",
    "print('\\nTraining Logistic Regression (L1)...')\n",
    "lr_l1 = LogisticRegression(\n",
    "    penalty='l1',\n",
    "    C=1.0,\n",
    "    max_iter=1000,\n",
    "    solver='saga',\n",
    "    random_state=42\n",
    ")\n",
    "lr_l1.fit(X_train_standard, y_train)\n",
    "lr_l1_pred = lr_l1.predict(X_test_standard)\n",
    "lr_l1_acc = accuracy_score(y_test, lr_l1_pred)\n",
    "lr_l1_f1 = f1_score(y_test, lr_l1_pred, average='weighted')\n",
    "linear_models['Logistic_L1'] = lr_l1\n",
    "linear_results.append({'Model': 'Logistic Regression (L1)', 'Accuracy': lr_l1_acc, 'F1-Score': lr_l1_f1})\n",
    "print(f'Accuracy: {lr_l1_acc:.4f}, F1-Score: {lr_l1_f1:.4f}')\n",
    "\n",
    "# 3. Logistic Regression with ElasticNet (L1 + L2)\n",
    "print('\\nTraining Logistic Regression (ElasticNet)...')\n",
    "lr_elastic = LogisticRegression(\n",
    "    penalty='elasticnet',\n",
    "    C=1.0,\n",
    "    l1_ratio=0.5,  # Mix of L1 and L2\n",
    "    max_iter=1000,\n",
    "    solver='saga',\n",
    "    random_state=42\n",
    ")\n",
    "lr_elastic.fit(X_train_standard, y_train)\n",
    "lr_elastic_pred = lr_elastic.predict(X_test_standard)\n",
    "lr_elastic_acc = accuracy_score(y_test, lr_elastic_pred)\n",
    "lr_elastic_f1 = f1_score(y_test, lr_elastic_pred, average='weighted')\n",
    "linear_models['Logistic_ElasticNet'] = lr_elastic\n",
    "linear_results.append({'Model': 'Logistic Regression (ElasticNet)', 'Accuracy': lr_elastic_acc, 'F1-Score': lr_elastic_f1})\n",
    "print(f'Accuracy: {lr_elastic_acc:.4f}, F1-Score: {lr_elastic_f1:.4f}')\n",
    "\n",
    "# 4. Ridge Classifier\n",
    "print('\\nTraining Ridge Classifier...')\n",
    "ridge = RidgeClassifier(alpha=1.0, random_state=42)\n",
    "ridge.fit(X_train_standard, y_train)\n",
    "ridge_pred = ridge.predict(X_test_standard)\n",
    "ridge_acc = accuracy_score(y_test, ridge_pred)\n",
    "ridge_f1 = f1_score(y_test, ridge_pred, average='weighted')\n",
    "linear_models['Ridge'] = ridge\n",
    "linear_results.append({'Model': 'Ridge Classifier', 'Accuracy': ridge_acc, 'F1-Score': ridge_f1})\n",
    "print(f'Accuracy: {ridge_acc:.4f}, F1-Score: {ridge_f1:.4f}')\n",
    "\n",
    "# Results summary\n",
    "print('\\n=== LINEAR MODELS SUMMARY ===\")\n",
    "linear_df = pd.DataFrame(linear_results)\n",
    "print(linear_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Regularized Tree-Based Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== REGULARIZED TREE-BASED MODELS ===\")\n",
    "print('Tree models use structural regularization (depth, min_samples, etc.)\\n')\n",
    "\n",
    "tree_models = {}\n",
    "tree_results = []\n",
    "\n",
    "# 1. Random Forest with regularization\n",
    "print('Training Random Forest (regularized)...')\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=15,  # Regularization: limit depth\n",
    "    min_samples_split=10,  # Regularization: minimum samples to split\n",
    "    min_samples_leaf=5,  # Regularization: minimum samples in leaf\n",
    "    max_features='sqrt',  # Regularization: feature sampling\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train_standard, y_train)\n",
    "rf_pred = rf.predict(X_test_standard)\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n",
    "rf_f1 = f1_score(y_test, rf_pred, average='weighted')\n",
    "tree_models['RandomForest'] = rf\n",
    "tree_results.append({'Model': 'Random Forest', 'Accuracy': rf_acc, 'F1-Score': rf_f1})\n",
    "print(f'Accuracy: {rf_acc:.4f}, F1-Score: {rf_f1:.4f}')\n",
    "\n",
    "# 2. Gradient Boosting with regularization\n",
    "print('\\nTraining Gradient Boosting (regularized)...')\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1,  # Regularization: smaller learning rate\n",
    "    max_depth=7,  # Regularization: limit depth\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    subsample=0.8,  # Regularization: stochastic gradient boosting\n",
    "    max_features='sqrt',\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train_standard, y_train)\n",
    "gb_pred = gb.predict(X_test_standard)\n",
    "gb_acc = accuracy_score(y_test, gb_pred)\n",
    "gb_f1 = f1_score(y_test, gb_pred, average='weighted')\n",
    "tree_models['GradientBoosting'] = gb\n",
    "tree_results.append({'Model': 'Gradient Boosting', 'Accuracy': gb_acc, 'F1-Score': gb_f1})\n",
    "print(f'Accuracy: {gb_acc:.4f}, F1-Score: {gb_f1:.4f}')\n",
    "\n",
    "# 3. XGBoost with regularization\n",
    "print('\\nTraining XGBoost (regularized)...')\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=7,\n",
    "    min_child_weight=3,  # Regularization\n",
    "    gamma=0.1,  # Regularization: minimum loss reduction\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,  # Regularization: feature sampling\n",
    "    reg_alpha=0.1,  # L1 regularization\n",
    "    reg_lambda=1.0,  # L2 regularization\n",
    "    random_state=42,\n",
    "    eval_metric='mlogloss'\n",
    ")\n",
    "xgb.fit(X_train_standard, y_train)\n",
    "xgb_pred = xgb.predict(X_test_standard)\n",
    "xgb_acc = accuracy_score(y_test, xgb_pred)\n",
    "xgb_f1 = f1_score(y_test, xgb_pred, average='weighted')\n",
    "tree_models['XGBoost'] = xgb\n",
    "tree_results.append({'Model': 'XGBoost', 'Accuracy': xgb_acc, 'F1-Score': xgb_f1})\n",
    "print(f'Accuracy: {xgb_acc:.4f}, F1-Score: {xgb_f1:.4f}')\n",
    "\n",
    "# 4. LightGBM with regularization\n",
    "print('\\nTraining LightGBM (regularized)...')\n",
    "lgbm = LGBMClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=7,\n",
    "    num_leaves=31,\n",
    "    min_child_samples=10,  # Regularization\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,  # L1\n",
    "    reg_lambda=1.0,  # L2\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "lgbm.fit(X_train_standard, y_train)\n",
    "lgbm_pred = lgbm.predict(X_test_standard)\n",
    "lgbm_acc = accuracy_score(y_test, lgbm_pred)\n",
    "lgbm_f1 = f1_score(y_test, lgbm_pred, average='weighted')\n",
    "tree_models['LightGBM'] = lgbm\n",
    "tree_results.append({'Model': 'LightGBM', 'Accuracy': lgbm_acc, 'F1-Score': lgbm_f1})\n",
    "print(f'Accuracy: {lgbm_acc:.4f}, F1-Score: {lgbm_f1:.4f}')\n",
    "\n",
    "# Results summary\n",
    "print('\\n=== TREE MODELS SUMMARY ===\")\n",
    "tree_df = pd.DataFrame(tree_results)\n",
    "print(tree_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Regularized Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== DEEP NEURAL NETWORK WITH REGULARIZATION ===\")\n",
    "print('Regularization techniques: L1/L2, Dropout, Batch Normalization\\n')\n",
    "\n",
    "# Build regularized DNN\n",
    "dnn = keras.Sequential([\n",
    "    # Input layer\n",
    "    layers.Dense(\n",
    "        128, \n",
    "        activation='relu', \n",
    "        input_shape=(X_train_standard.shape[1],),\n",
    "        kernel_regularizer=regularizers.l2(0.001)  # L2 regularization\n",
    "    ),\n",
    "    layers.BatchNormalization(),  # Batch normalization\n",
    "    layers.Dropout(0.4),  # Dropout regularization\n",
    "    \n",
    "    # Hidden layer 1\n",
    "    layers.Dense(\n",
    "        64, \n",
    "        activation='relu',\n",
    "        kernel_regularizer=regularizers.l1_l2(l1=0.0001, l2=0.001)  # L1+L2\n",
    "    ),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    # Hidden layer 2\n",
    "    layers.Dense(\n",
    "        32, \n",
    "        activation='relu',\n",
    "        kernel_regularizer=regularizers.l2(0.001)\n",
    "    ),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.2),\n",
    "    \n",
    "    # Output layer\n",
    "    layers.Dense(4, activation='softmax')  # 4 classes\n",
    "])\n",
    "\n",
    "# Compile\n",
    "dnn.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "dnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks for regularization\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=7,\n",
    "    min_lr=0.00001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train\n",
    "print('Training DNN with regularization...')\n",
    "history = dnn.fit(\n",
    "    X_train_standard, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "dnn_pred_proba = dnn.predict(X_test_standard)\n",
    "dnn_pred = np.argmax(dnn_pred_proba, axis=1)\n",
    "dnn_acc = accuracy_score(y_test, dnn_pred)\n",
    "dnn_f1 = f1_score(y_test, dnn_pred, average='weighted')\n",
    "\n",
    "print(f'\\nDNN Accuracy: {dnn_acc:.4f}')\n",
    "print(f'DNN F1-Score: {dnn_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "axes[0].plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontweight='bold')\n",
    "axes[0].set_ylabel('Loss', fontweight='bold')\n",
    "axes[0].set_title('Training and Validation Loss', fontweight='bold', fontsize=14)\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "axes[1].plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontweight='bold')\n",
    "axes[1].set_ylabel('Accuracy', fontweight='bold')\n",
    "axes[1].set_title('Training and Validation Accuracy', fontweight='bold', fontsize=14)\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Epochs trained: {len(history.history[\"loss\"])}')\n",
    "print(f'Best validation accuracy: {max(history.history[\"val_accuracy\"]):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== HYPERPARAMETER TUNING ===\")\n",
    "print('Using RandomizedSearchCV for efficient search\\n')\n",
    "\n",
    "# Define parameter distributions for XGBoost\n",
    "xgb_param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [5, 7, 9, 11],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'reg_alpha': [0, 0.01, 0.1],\n",
    "    'reg_lambda': [0.5, 1.0, 2.0]\n",
    "}\n",
    "\n",
    "# Randomized search\n",
    "xgb_random = RandomizedSearchCV(\n",
    "    XGBClassifier(random_state=42, eval_metric='mlogloss'),\n",
    "    param_distributions=xgb_param_dist,\n",
    "    n_iter=50,  # Number of parameter combinations to try\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "print('Tuning XGBoost (this may take a few minutes)...')\n",
    "xgb_random.fit(X_train_standard, y_train)\n",
    "\n",
    "print(f'\\nBest parameters: {xgb_random.best_params_}')\n",
    "print(f'Best CV score: {xgb_random.best_score_:.4f}')\n",
    "\n",
    "# Evaluate tuned model\n",
    "xgb_tuned = xgb_random.best_estimator_\n",
    "xgb_tuned_pred = xgb_tuned.predict(X_test_standard)\n",
    "xgb_tuned_acc = accuracy_score(y_test, xgb_tuned_pred)\n",
    "xgb_tuned_f1 = f1_score(y_test, xgb_tuned_pred, average='weighted')\n",
    "\n",
    "print(f'\\nTuned XGBoost Test Accuracy: {xgb_tuned_acc:.4f}')\n",
    "print(f'Tuned XGBoost Test F1-Score: {xgb_tuned_f1:.4f}')\n",
    "print(f'\\nImprovement over default: {(xgb_tuned_acc - xgb_acc)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== ENSEMBLE METHODS ===\")\n",
    "\n",
    "# Voting Classifier (soft voting)\n",
    "print('Training Voting Classifier...')\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', xgb_tuned),\n",
    "        ('lgbm', lgbm),\n",
    "        ('rf', rf),\n",
    "        ('gb', gb)\n",
    "    ],\n",
    "    voting='soft',\n",
    "    n_jobs=-1\n",
    ")\n",
    "voting_clf.fit(X_train_standard, y_train)\n",
    "voting_pred = voting_clf.predict(X_test_standard)\n",
    "voting_acc = accuracy_score(y_test, voting_pred)\n",
    "voting_f1 = f1_score(y_test, voting_pred, average='weighted')\n",
    "print(f'Voting Classifier Accuracy: {voting_acc:.4f}, F1-Score: {voting_f1:.4f}')\n",
    "\n",
    "# Stacking Classifier\n",
    "print('\\nTraining Stacking Classifier...')\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', xgb_tuned),\n",
    "        ('lgbm', lgbm),\n",
    "        ('rf', rf),\n",
    "        ('gb', gb)\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(max_iter=1000),\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "stacking_clf.fit(X_train_standard, y_train)\n",
    "stacking_pred = stacking_clf.predict(X_test_standard)\n",
    "stacking_acc = accuracy_score(y_test, stacking_pred)\n",
    "stacking_f1 = f1_score(y_test, stacking_pred, average='weighted')\n",
    "print(f'Stacking Classifier Accuracy: {stacking_acc:.4f}, F1-Score: {stacking_f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Comparison and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all results\n",
    "all_results = [\n",
    "    {'Model': 'Logistic Regression (L2)', 'Accuracy': lr_l2_acc, 'F1-Score': lr_l2_f1, 'Category': 'Linear'},\n",
    "    {'Model': 'Logistic Regression (L1)', 'Accuracy': lr_l1_acc, 'F1-Score': lr_l1_f1, 'Category': 'Linear'},\n",
    "    {'Model': 'Logistic Regression (ElasticNet)', 'Accuracy': lr_elastic_acc, 'F1-Score': lr_elastic_f1, 'Category': 'Linear'},\n",
    "    {'Model': 'Ridge Classifier', 'Accuracy': ridge_acc, 'F1-Score': ridge_f1, 'Category': 'Linear'},\n",
    "    {'Model': 'Random Forest', 'Accuracy': rf_acc, 'F1-Score': rf_f1, 'Category': 'Tree'},\n",
    "    {'Model': 'Gradient Boosting', 'Accuracy': gb_acc, 'F1-Score': gb_f1, 'Category': 'Tree'},\n",
    "    {'Model': 'XGBoost', 'Accuracy': xgb_acc, 'F1-Score': xgb_f1, 'Category': 'Tree'},\n",
    "    {'Model': 'LightGBM', 'Accuracy': lgbm_acc, 'F1-Score': lgbm_f1, 'Category': 'Tree'},\n",
    "    {'Model': 'XGBoost (Tuned)', 'Accuracy': xgb_tuned_acc, 'F1-Score': xgb_tuned_f1, 'Category': 'Tree'},\n",
    "    {'Model': 'Deep Neural Network', 'Accuracy': dnn_acc, 'F1-Score': dnn_f1, 'Category': 'Deep Learning'},\n",
    "    {'Model': 'Voting Ensemble', 'Accuracy': voting_acc, 'F1-Score': voting_f1, 'Category': 'Ensemble'},\n",
    "    {'Model': 'Stacking Ensemble', 'Accuracy': stacking_acc, 'F1-Score': stacking_f1, 'Category': 'Ensemble'}\n",
    "]\n",
    "\n",
    "results_df = pd.DataFrame(all_results).sort_values('Accuracy', ascending=False)\n",
    "\n",
    "print('=== FINAL MODEL COMPARISON ===\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv('final_model_comparison_complete.csv', index=False)\n",
    "print('\\nResults saved to: final_model_comparison_complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "\n",
    "# Plot 1: Accuracy comparison\n",
    "results_sorted = results_df.sort_values('Accuracy', ascending=True)\n",
    "colors = ['#3498DB' if cat == 'Linear' else '#2ECC71' if cat == 'Tree' \n",
    "          else '#9B59B6' if cat == 'Deep Learning' else '#E74C3C' \n",
    "          for cat in results_sorted['Category']]\n",
    "axes[0, 0].barh(range(len(results_sorted)), results_sorted['Accuracy'], color=colors, alpha=0.8)\n",
    "axes[0, 0].set_yticks(range(len(results_sorted)))\n",
    "axes[0, 0].set_yticklabels(results_sorted['Model'], fontsize=9)\n",
    "axes[0, 0].set_xlabel('Accuracy', fontweight='bold')\n",
    "axes[0, 0].set_title('Model Comparison: Accuracy', fontweight='bold', fontsize=14)\n",
    "axes[0, 0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Plot 2: F1-Score comparison\n",
    "results_sorted_f1 = results_df.sort_values('F1-Score', ascending=True)\n",
    "colors_f1 = ['#3498DB' if cat == 'Linear' else '#2ECC71' if cat == 'Tree' \n",
    "             else '#9B59B6' if cat == 'Deep Learning' else '#E74C3C' \n",
    "             for cat in results_sorted_f1['Category']]\n",
    "axes[0, 1].barh(range(len(results_sorted_f1)), results_sorted_f1['F1-Score'], color=colors_f1, alpha=0.8)\n",
    "axes[0, 1].set_yticks(range(len(results_sorted_f1)))\n",
    "axes[0, 1].set_yticklabels(results_sorted_f1['Model'], fontsize=9)\n",
    "axes[0, 1].set_xlabel('F1-Score', fontweight='bold')\n",
    "axes[0, 1].set_title('Model Comparison: F1-Score', fontweight='bold', fontsize=14)\n",
    "axes[0, 1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Plot 3: Category-wise average\n",
    "category_avg = results_df.groupby('Category')[['Accuracy', 'F1-Score']].mean()\n",
    "x_pos = np.arange(len(category_avg))\n",
    "width = 0.35\n",
    "axes[1, 0].bar(x_pos - width/2, category_avg['Accuracy'], width, label='Accuracy', alpha=0.8)\n",
    "axes[1, 0].bar(x_pos + width/2, category_avg['F1-Score'], width, label='F1-Score', alpha=0.8)\n",
    "axes[1, 0].set_xticks(x_pos)\n",
    "axes[1, 0].set_xticklabels(category_avg.index)\n",
    "axes[1, 0].set_ylabel('Score', fontweight='bold')\n",
    "axes[1, 0].set_title('Average Performance by Category', fontweight='bold', fontsize=14)\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 4: Top 5 models\n",
    "top5 = results_df.head(5)\n",
    "x_pos5 = np.arange(len(top5))\n",
    "axes[1, 1].bar(x_pos5 - width/2, top5['Accuracy'], width, label='Accuracy', alpha=0.8, color='green')\n",
    "axes[1, 1].bar(x_pos5 + width/2, top5['F1-Score'], width, label='F1-Score', alpha=0.8, color='blue')\n",
    "axes[1, 1].set_xticks(x_pos5)\n",
    "axes[1, 1].set_xticklabels(top5['Model'], rotation=15, ha='right', fontsize=9)\n",
    "axes[1, 1].set_ylabel('Score', fontweight='bold')\n",
    "axes[1, 1].set_title('Top 5 Models', fontweight='bold', fontsize=14)\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison_visualization.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('Visualization saved to: model_comparison_visualization.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Best Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best model\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_accuracy = results_df.iloc[0]['Accuracy']\n",
    "best_f1 = results_df.iloc[0]['F1-Score']\n",
    "\n",
    "print('='*80)\n",
    "print('BEST MODEL')\n",
    "print('='*80)\n",
    "print(f'Model: {best_model_name}')\n",
    "print(f'Accuracy: {best_accuracy:.4f}')\n",
    "print(f'F1-Score: {best_f1:.4f}')\n",
    "print('='*80)\n",
    "\n",
    "# Get predictions from best model\n",
    "if best_model_name == 'Voting Ensemble':\n",
    "    best_model = voting_clf\n",
    "    best_pred = voting_pred\n",
    "elif best_model_name == 'Stacking Ensemble':\n",
    "    best_model = stacking_clf\n",
    "    best_pred = stacking_pred\n",
    "elif best_model_name == 'XGBoost (Tuned)':\n",
    "    best_model = xgb_tuned\n",
    "    best_pred = xgb_tuned_pred\n",
    "elif best_model_name == 'Deep Neural Network':\n",
    "    best_model = dnn\n",
    "    best_pred = dnn_pred\n",
    "elif best_model_name == 'XGBoost':\n",
    "    best_model = xgb\n",
    "    best_pred = xgb_pred\n",
    "elif best_model_name == 'LightGBM':\n",
    "    best_model = lgbm\n",
    "    best_pred = lgbm_pred\n",
    "elif best_model_name == 'Gradient Boosting':\n",
    "    best_model = gb\n",
    "    best_pred = gb_pred\n",
    "elif best_model_name == 'Random Forest':\n",
    "    best_model = rf\n",
    "    best_pred = rf_pred\n",
    "else:\n",
    "    # Linear models\n",
    "    best_model = lr_l2\n",
    "    best_pred = lr_l2_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed classification report\n",
    "print('\\n=== CLASSIFICATION REPORT ===\")\n",
    "print(classification_report(\n",
    "    y_test, best_pred, \n",
    "    target_names=['Risk Level 0', 'Risk Level 1', 'Risk Level 2', 'Risk Level 3']\n",
    "))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, best_pred)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Confusion matrix heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0], \n",
    "            xticklabels=['Risk 0', 'Risk 1', 'Risk 2', 'Risk 3'],\n",
    "            yticklabels=['Risk 0', 'Risk 1', 'Risk 2', 'Risk 3'])\n",
    "axes[0].set_xlabel('Predicted', fontweight='bold')\n",
    "axes[0].set_ylabel('Actual', fontweight='bold')\n",
    "axes[0].set_title(f'{best_model_name} - Confusion Matrix', fontweight='bold', fontsize=14)\n",
    "\n",
    "# Normalized confusion matrix\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm_norm, annot=True, fmt='.2%', cmap='Greens', ax=axes[1],\n",
    "            xticklabels=['Risk 0', 'Risk 1', 'Risk 2', 'Risk 3'],\n",
    "            yticklabels=['Risk 0', 'Risk 1', 'Risk 2', 'Risk 3'])\n",
    "axes[1].set_xlabel('Predicted', fontweight='bold')\n",
    "axes[1].set_ylabel('Actual', fontweight='bold')\n",
    "axes[1].set_title(f'{best_model_name} - Normalized Confusion Matrix', fontweight='bold', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('best_model_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance (if available)\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print('\\n=== TOP 20 MOST IMPORTANT FEATURES ===\")\n",
    "    print(feature_importance.head(20).to_string(index=False))\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top20 = feature_importance.head(20)\n",
    "    plt.barh(range(len(top20)), top20['importance'], color='steelblue', alpha=0.8)\n",
    "    plt.yticks(range(len(top20)), top20['feature'], fontsize=9)\n",
    "    plt.xlabel('Importance', fontweight='bold')\n",
    "    plt.title(f'{best_model_name} - Feature Importance', fontweight='bold', fontsize=14)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('best_model_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Save feature importance\n",
    "    feature_importance.to_csv('best_model_feature_importance.csv', index=False)\n",
    "    print('\\nFeature importance saved to: best_model_feature_importance.csv')\n",
    "else:\n",
    "    print('\\nFeature importance not available for this model type.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Cross-Validation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation on best model\n",
    "if best_model_name != 'Deep Neural Network':  # CV is tricky with Keras\n",
    "    print('=== CROSS-VALIDATION ANALYSIS ===\")\n",
    "    print(f'Running 10-fold stratified CV on {best_model_name}...\\n')\n",
    "    \n",
    "    cv_scores = cross_val_score(\n",
    "        best_model, X_train_standard, y_train,\n",
    "        cv=StratifiedKFold(n_splits=10, shuffle=True, random_state=42),\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    print(f'CV Scores: {cv_scores}')\n",
    "    print(f'\\nMean CV Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})')\n",
    "    print(f'Min: {cv_scores.min():.4f}')\n",
    "    print(f'Max: {cv_scores.max():.4f}')\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.boxplot(cv_scores, vert=False)\n",
    "    plt.axvline(cv_scores.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {cv_scores.mean():.4f}')\n",
    "    plt.xlabel('Accuracy', fontweight='bold')\n",
    "    plt.title(f'{best_model_name} - 10-Fold Cross-Validation', fontweight='bold', fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Cross-validation analysis not performed for Deep Neural Network.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "print('=== SAVING BEST MODEL ===\")\n",
    "\n",
    "# Save model\n",
    "if best_model_name == 'Deep Neural Network':\n",
    "    best_model.save('best_model_true_risk.h5')\n",
    "    print(f'Model saved to: best_model_true_risk.h5')\n",
    "else:\n",
    "    joblib.dump(best_model, 'best_model_true_risk.pkl')\n",
    "    print(f'Model saved to: best_model_true_risk.pkl')\n",
    "\n",
    "# Save scaler\n",
    "joblib.dump(scaler_standard, 'scaler_standard.pkl')\n",
    "print(f'Scaler saved to: scaler_standard.pkl')\n",
    "\n",
    "# Save feature columns\n",
    "joblib.dump(feature_cols, 'feature_columns.pkl')\n",
    "print(f'Feature columns saved to: feature_columns.pkl')\n",
    "\n",
    "# Save label encoders\n",
    "joblib.dump(le_country, 'label_encoder_country.pkl')\n",
    "joblib.dump(le_reactor, 'label_encoder_reactor.pkl')\n",
    "print('Label encoders saved.')\n",
    "\n",
    "print('\\nAll artifacts saved successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*80)\n",
    "print('FINAL SUMMARY: TRUE RISK LEVEL PREDICTION')\n",
    "print('='*80)\n",
    "\n",
    "print(f'\\n1. DATASET:')\n",
    "print(f'   - Total samples: {len(df):,}')\n",
    "print(f'   - Train samples: {len(X_train):,}')\n",
    "print(f'   - Test samples: {len(X_test):,}')\n",
    "print(f'   - Total features: {len(feature_cols)}')\n",
    "print(f'   - Target classes: 4 (Risk levels 0-3)')\n",
    "\n",
    "print(f'\\n2. TECHNIQUES APPLIED:')\n",
    "print(f'   âœ“ Feature Engineering (20+ new features)')\n",
    "print(f'   âœ“ Multiple Normalization Methods (Standard, MinMax, Robust)')\n",
    "print(f'   âœ“ Feature Selection (SelectKBest, F-test)')\n",
    "print(f'   âœ“ Regularization:')\n",
    "print(f'     - L1 (Lasso) for linear models')\n",
    "print(f'     - L2 (Ridge) for linear models')\n",
    "print(f'     - ElasticNet (L1 + L2)')\n",
    "print(f'     - Structural regularization for tree models')\n",
    "print(f'     - L1/L2 + Dropout + BatchNorm for neural networks')\n",
    "print(f'   âœ“ Hyperparameter Tuning (RandomizedSearchCV)')\n",
    "print(f'   âœ“ Cross-Validation (Stratified K-Fold)')\n",
    "print(f'   âœ“ Ensemble Methods (Voting, Stacking)')\n",
    "\n",
    "print(f'\\n3. MODELS EVALUATED:')\n",
    "print(f'   - Linear Models: 4')\n",
    "print(f'   - Tree Models: 5')\n",
    "print(f'   - Deep Learning: 1')\n",
    "print(f'   - Ensemble: 2')\n",
    "print(f'   - Total: {len(results_df)}')\n",
    "\n",
    "print(f'\\n4. BEST MODEL:')\n",
    "print(f'   - Name: {best_model_name}')\n",
    "print(f'   - Test Accuracy: {best_accuracy:.4f} ({best_accuracy*100:.2f}%)')\n",
    "print(f'   - Test F1-Score: {best_f1:.4f}')\n",
    "\n",
    "print(f'\\n5. TOP 5 MODELS:')\n",
    "for idx, row in results_df.head(5).iterrows():\n",
    "    print(f'   {idx+1}. {row[\"Model\"]}: {row[\"Accuracy\"]:.4f}')\n",
    "\n",
    "print(f'\\n6. OUTPUTS GENERATED:')\n",
    "print(f'   âœ“ final_model_comparison_complete.csv')\n",
    "print(f'   âœ“ model_comparison_visualization.png')\n",
    "print(f'   âœ“ best_model_confusion_matrix.png')\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    print(f'   âœ“ best_model_feature_importance.png')\n",
    "    print(f'   âœ“ best_model_feature_importance.csv')\n",
    "if best_model_name == 'Deep Neural Network':\n",
    "    print(f'   âœ“ best_model_true_risk.h5')\n",
    "else:\n",
    "    print(f'   âœ“ best_model_true_risk.pkl')\n",
    "print(f'   âœ“ scaler_standard.pkl')\n",
    "print(f'   âœ“ feature_columns.pkl')\n",
    "print(f'   âœ“ label_encoder_*.pkl')\n",
    "\n",
    "print(f'\\n7. REGULARIZATION IMPACT:')\n",
    "print(f'   - Prevented overfitting through multiple techniques')\n",
    "print(f'   - Improved generalization to unseen data')\n",
    "print(f'   - Enhanced model robustness and stability')\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('\"Success is not final; failure is not fatal: It is the courage to continue\"')\n",
    "print('- Winston S. Churchill')\n",
    "print('='*80)\n",
    "\n",
    "print(f'\\nðŸŽ‰ COMPREHENSIVE MODEL TRAINING COMPLETE! ðŸŽ‰')\n",
    "print(f'Best model achieves {best_accuracy*100:.2f}% accuracy on true risk prediction.')\n",
    "print(f'Ready for deployment and production use!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
